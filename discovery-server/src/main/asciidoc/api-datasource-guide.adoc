
[[resources-datasource]]
== DataSource


[[resources-datasource-representations]]
=== Resource representations

.DataSource
|===
|Name |Type |Description |Note

|id
|String
|Datasource Id, Generated value, UUID
|

|name
|String
|DataSource Name,
ENGINE 타입인 경우 ENGINE 내 DataSource 중복 방지를 위해 내부 룰에 따라 이름 변경 postfix 로 Timestamp 를 추가
하고 표시이름(alias)를 활용
|writable (POST)

|alias
|String
|데이터 소스 표시이름
|writable

|description
|String
|데이터 소스 설명
|writable

|owner
|UserProfile
|데이터 소스 생성자 정보
|

|owner.username
|Object
|생성자 username
|

|owner.fullName
|Object
|생성자 명
|

|owner.email
|Object
|생성자 email
|

|dsType
|Enum
|데이터소스 스키마 유형, MASTER/LOOKUP
|writable (POST)

|connType
|Enum
|데이터소스 연결 유형, 수집형(ENGINE)/연결형(LIVE)
|writable (POST)

|srcType
|Enum
|데이터소스 연결 유형, 수집형(ENGINE)/연결형(LIVE)
|writable (POST)

|granularity
|Enum
|시간 필드에 대한 집계의 최소 단위, SECOND/MINUTE/HOUR/DAY/WEEK/MONTH/QUARTER/YEAR
|writable

|segGranularity
|Enum
|connType 가 ENGINE 타입의 경우만 해당, 엔진내 저장 단위
|writable (POST)

|status
|Enum
|데이터소스 상태, 사용가능(ENABLED)/일부사용 불가(BAD)/준비중(PREPARING)/적재 실패(FAILED)/사용 불가(DISABLED)
|

|published
|Boolean
|데이터소스 전체 공개 여부
|writable

|workspaces[]
|Workspace
|published 가 false 인 경우 유효, 데이터소스가 사용가능한 Workspace 정보
|

|connection
|DataConnection
|데이터소스가 참조하고 있는 연결 정보, 수집형일 경우 적재시 연결 정보이며 연결형일 경우 연결 정보
|writable (POST, Resource URL)

|ingestion
|DataIngestion
|데이터 소스 적재 정보, 수집형일 경우 적재 정보이며, 연결형일 경우 추가 정보
|

|ingestion.ingestionMinTime
|DateTime
|수집형인 경우만 적용, Timestamp 필드 from
|

|ingestion.ingestionMaxTime
|DateTime
|수집형인 경우만 적용, Timestamp 필드 to
|

|ingestion.size
|Long
|수집형인 경우만 적용, 수집된 데이터 사이즈
|

|ingestion.count
|Long
|수집형인 경우만 적용, 수집된 데이터 row count
|

|ingestion.info
|IngestionInfo
|데이터 소스 적재 상세 정보
|writable (POST)

|fields[]
|Field
|데이터 소스내 필드 정보
|writable (POST)

|fields[].name
|String
|필드 명
|

|fields[].type
|Enum
|데이터 타입, 문자형(TEXT)/BOOLEAN/정수형(INT/LONG)/실수형(FLOAT/DOUBLE)/TIMESTAMP
|

|fields[].biType
|Enum
|OLAP 타입
|

|fields[].seq
|Long
|필드 정렬 순서
|

|fields[].filtering
|Boolean
|필수 필터 여부
|

|fields[].filteringSeq
|Long
|필수 필터 순서
|

|fields[].aggrType
|Enum
|수집형인 경우 지정 가능, 사전 집계 타입, NONE/MIN/MAX/COUNT/SUM/AVG/STDDEV/MEDIAN/AREA/RANGE/QUANTILE
|

|===

.IngestionInfo
|===
|Name |Type |Description |Note

|type
|String
|적재 타입, 로컬파일(local), HDFS(hdfs), 실시간(realtime), JDBC(single, batch, live)
|

|format
|FileFormat
|적재될 파일(or 데이터) 형태
|

|format.type
|String
|csv/excel/json/orc
|

|format.delimeter
|String
|csv 형태일 경우, 컬럼 구분자
|

|format.lineSeparator
|String
|csv 형태일 경우, 라인 구분자
|

|format.sheetIndex
|String
|excel 형태일 경우, Sheet Index 지정
|

|dataType
|Enum
|JDBC 형태일 경우 적재될 데이터 형태, QUERY/TABLE
|

|schema
|String
|JDBC 형태이고, dataType이 TABLE 인 경우, DB 내 Schema 명 기입
|

|query
|String
|JDBC 형태일 경우, dataType이 TABLE 인 경우 Table 명/ QUERY 인 경우 query 구분 기입
|

|path
|String
|Local File 형태일 경우, 적재할 파일 경로 (서버가 인식할 수 있는 Path)
|

|removeFirstRow
|String
|Local File 형태일 경우, 컬럼 헤더가 존재하는 경우 true
|

|removeFirstRow
|String
|Local File 형태일 경우, 컬럼 헤더가 존재하는 경우 true
|

|paths
|String
|HDFS 형태일 경우, 적재할 경로 목록
|

|findRecursive
|Boolean
|HDFS 형태일 경우, 경로중 디렉토리일 경우, 하위 디렉토리 파일도 적재 목록에 포함 여부
|

|jobProperties
|Map
|적재시 수행하는 MR Job 속성 Overwrite
|

|===

[[resources-datasource-representations-projections]]
==== Projection Models


[[resources-datasource-methods]]
=== Methods


[[resources-datasource-methods-list]]
==== List

Returns datasources on the specified conditions.

===== HTTP request
    (GET) /api/datasources(?projection)

===== Parameters
.Optional query parameters
|===
|Parameter Name |Type |Description |Note

|connType
|string
|The type of connection - ENGINE, LINK
|

|srcType
|string
|The type of origin source (FILE/JDBC/HDFS/HIVE/REALTIME)
|

|published
|boolean
|전체 공개 여부
|

|nameContains
|string
|데이터 소스명 내 포함되는 문자
|

|searchDateBy
|string
|생성일(CREATED)/수정일(MODIFIED) 기준 여부
|

|from
|string
|검색 시작일자, ISO DATE_TIME(yyyy-MM-ddTHH:mm:dd.SSSZ) 형식
|

|from
|string
|검색 종료일자, ISO DATE_TIME(yyyy-MM-ddTHH:mm:dd.SSSZ) 형식
|

|===

===== Response
If successful, this method returns list of [#resources-datasource-representations-projections]#projection model# in the response body.

[[resources-datasource-methods-get]]
==== Get
Returns a datasource.

===== HTTP request
    (GET) /api/datasources/{datasourceId}(?projection)

===== Parameters
.Path parameters
|===
|Parameter Name |Type |Description |Note

|datasoureId
|string
|datasource Id
|

|===

===== Response
If successful, this method returns [#resources-datasource-representations-projections]#projection model# in the response body.

[[resources-datasource-methods-create]]
==== Create

Creates a DataSource

===== HTTP request
    (POST) /api/datasources

===== Parameters
None

===== Request Body

.Request body structure
[source,json]
----
{
  "name": "string",
  "description": "string",
  "dsType": "enum",
  "connType": "enum",
  "srcType": "enum",
  "granularity": "enum",
  "segGranularity": "enum",
  "published": false,
  "connection": "/api/connections/{connectionId}",
  "fields": [
    {
      "seq": 0,
      "name": "string",
      "alias": "string",
      "description": "string",
      "type": "enum",
      "role": "enum",
      "aggrType": "enum",
      "filtering": false,
      "filteringSeq": 0
    }
  ],
  "ingestion": {
    "info": {
      "type": "string",
      "dataType": "enum",
      "schema": "string",
      "query": "string",
      "path": "string",
      "removeFirstRow": false,
      "paths": ["string"],
      "findRecursive": false,
      "jobProperties": {"key": "value"},
      "format": {
        "type": "string",
        "delimeter": "string",
        "lineSeparator": "string",
        "sheetIndex": 0
      }
    }
  }
}
----

.Request body sample - for JDBC
[source,json]
----
{
  "name": "JDBCIngestion",
  "dsType": "MASTER",
  "connType": "ENGINE",
  "srcType": "JDBC",
  "granularity": "DAY",
  "segGranularity": "MONTH",
  "connection": "/api/connections/mysql-connection",
  "fields": [
    {
      "name": "time",
      "type": "TIMESTAMP",
      "role": "TIMESTAMP",
      "seq": 0
    },
    {
      "name": "d",
      "type": "TEXT",
      "role": "DIMENSION",
      "seq": 1
    },
    {
      "name": "m1",
      "type": "DOUBLE",
      "role": "MEASURE",
      "aggrType": "SUM",
      "seq": 2
    }
  ],
  "ingestion": {
    "info": {
      "type": "single",
      "schema": "polaris_datasources",
      "dataType": "TABLE",
      "query": "sample_ingestion"
    }
  }
}
----

.Request body sample - for Local File
[source,json]
----
{
  "name": "localFileIngestion",
  "alias": "localFileIngestion",
  "dsType": "MASTER",
  "connType": "ENGINE",
  "srcType": "FILE",
  "granularity": "DAY",
  "segGranularity": "MONTH",
  "fields": [
    {
      "name": "time",
      "type": "TIMESTAMP",
      "role": "TIMESTAMP",
      "seq": 0
    },
    {
      "name": "d",
      "type": "TEXT",
      "role": "DIMENSION",
      "seq": 1
    },
    {
      "name": "m1",
      "type": "DOUBLE",
      "role": "MEASURE",
      "aggrType": "SUM",
      "seq": 2
    }
  ],
  "ingestion": {
    "info": {
      "type": "local",
      "path": "/tmp/sample_ingestion.csv",
      "removeFirstRow": false,
      "format": {
        "type": "csv"
      }
    }
  }
}
----

.Request body sample - for HDFS
[source,json]
----
{
  "name": "HdfsFileIngestion",
  "alias": "HdfsFileIngestion",
  "dsType": "MASTER",
  "connType": "ENGINE",
  "srcType": "HDFS",
  "granularity": "DAY",
  "segGranularity": "MONTH",
  "fields": [
    {
      "name": "time",
      "type": "TIMESTAMP",
      "role": "TIMESTAMP",
      "seq": 0
    },
    {
      "name": "d",
      "type": "TEXT",
      "role": "DIMENSION",
      "seq": 1
    },
    {
      "name": "m1",
      "type": "DOUBLE",
      "role": "MEASURE",
      "aggrType": "SUM",
      "seq": 2
    }
  ],
  "ingestion": {
    "info": {
      "type": "hdfs",
      "paths": [
        "/tmp/sample_ingestion.csv"
      ],
      "findRecursive": false,
      "format": {
        "type": "csv"
      },
      "jobProperties": {
        "mapreduce.map.memory.mb": "1024",
        "mapreduce.reduce.memory.mb": "1024",
        "mapreduce.map.cpu.vcores": "1",
        "mapreduce.reduce.cpu.vcores": "1"
      }
    }
  }
}
----

.Request body sample - for Hive
[source,json]
----
{
    "name": "Hive Ingestion orc partition bffcg",
    "dsType": "MASTER",
    "connType": "ENGINE",
    "srcType": "HIVE",
    "granularity": "DAY",
    "segGranularity": "MONTH",
    "linkedWorkspaces": 0,
    "ingestion": {
        "type": "hive",
        "format": {
            "type": "orc"
        },
        "source": "default.sample_ingestion_partition_parti_orc",
        "partitions": [
            {
                "dd": "21",
                "ym": "201704"
            },
            {
                "ym": "201705"
            }
        ],
        "intervals": [
            "1979-12-12/2050-01-01"
        ]
    },
    "fields": [
        {
            "name": "time",
            "alias": "time",
            "type": "TIMESTAMP",
            "logicalType": "TIMESTAMP",
            "role": "TIMESTAMP",
            "aggrType": "NONE",
            "seq": 0,
            "biType": "TIMESTAMP"
        },
        {
            "name": "d",
            "alias": "d",
            "type": "STRING",
            "logicalType": "STRING",
            "role": "DIMENSION",
            "aggrType": "NONE",
            "seq": 1,
            "biType": "DIMENSION"
        },
        {
            "name": "sd",
            "alias": "sd",
            "type": "STRING",
            "logicalType": "STRING",
            "role": "DIMENSION",
            "aggrType": "NONE",
            "seq": 2,
            "biType": "DIMENSION"
        },
        {
            "name": "m1",
            "alias": "m1",
            "type": "DOUBLE",
            "logicalType": "DOUBLE",
            "role": "MEASURE",
            "aggrType": "NONE",
            "seq": 3,
            "biType": "MEASURE"
        },
        {
            "name": "m2",
            "alias": "m2",
            "type": "DOUBLE",
            "logicalType": "DOUBLE",
            "role": "MEASURE",
            "aggrType": "NONE",
            "seq": 4,
            "biType": "MEASURE"
        }
    ]
}
----

.Request body sample - for real time
[source,json]
----
{
    "name": "RealTime Ingestion",
    "dsType": "MASTER",
    "connType": "ENGINE",
    "srcType": "REALTIME",
    "granularity": "SECOND",
    "segGranularity": "HOUR",
    "ingestion": {
        "type": "realtime",
        "topic": "test_topic",
        "consumerType": "KAFKA",
        "consumerProperties": {
            "bootstrap.servers": "localhost:9092"
        },
        "format": {
            "type": "json"
        },
        "rollup": false
    },
    "fields": [
        {
            "name": "event_time",
            "type": "TIMESTAMP",
            "role": "TIMESTAMP",
            "seq": 0
        },
        {
            "name": "d1",
            "type": "STRING",
            "role": "DIMENSION",
            "seq": 1
        },
        {
            "name": "d2",
            "type": "STRING",
            "role": "DIMENSION"
            "seq": 2
        },
        {
            "name": "m1",
            "type": "DOUBLE",
            "role": "MEASURE",
            "seq": 3
        },
        {
            "name": "m2",
            "type": "DOUBLE",
            "role": "MEASURE",
            "seq": 4
        }
    ]
}
----

===== Response

If successful, this method returns a Datasource resource in the response body and `201` status.

[[resources-datasource-methods-update]]
==== Update

Updates a datasource, This method supports patch semantics.
The field values you specify replace the existing values.

===== HTTP request
    (PATCH) /api/datasources/{datasourceId}

===== Parameters
.Path parameters
|===
|Parameter Name |Type |Description |Note

|datasoureId
|string
|datasource Id

|
|===

===== Request Body

.Request body structure
[source,json]
----
{
  "name": "string",
  "description": "string",
  "published": false
}
----

===== Response
If successful, this method returns a Datasource resource in the response body.

[[resources-datasource-methods-delete]]
==== Delete

Deletes a datasource

===== HTTP request
    (DELETE) /api/datasources/{datasourceId}

===== Parameters
.Path parameters
|===
|Parameter Name |Type |Description |Note

|datasoureId
|string
|datasource Id

|===

===== Request body
Do not supply a request body with this method.

===== Response

If successful, this method returns an empty response body and `204` status.